---
semester: "Wintersemester 2024/25"
course: "Fortgeschrittene mathematische Methoden in der Statistik"
course-short: "FMM"
instructor: "Prof. Dr. Example, Dr. Assistant"
date: "15.02.2025"
duration: 90
exam-lang: de
grid-paper: true
extra-pages: 2
format: exam-pdf
---

{{< include hinweise.qmd >}}

## Maximum-Likelihood-Schätzer

Zeigen Sie, dass der folgende Ausdruck der Maximum-Likelihood-Schätzer für die Varianz einer Normalverteilung ist:
$$ \hat{\sigma}^2 = \frac{1}{n} \sum_{i=1}^n (x_i-\bar{x})^2$$

::: {.solution box=4}
**Lösung:**

Die Likelihood-Funktion für eine Normalverteilung ist: \p
$$L(\mu, \sigma^2) = \prod_{i=1}^n \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(x_i-\mu)^2}{2\sigma^2}\right)$$

Log-Likelihood aufstellen: \p
$$\ell(\mu, \sigma^2) = -\frac{n}{2}\ln(2\pi) - \frac{n}{2}\ln(\sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^n (x_i-\mu)^2$$

Ableitung nach $\sigma^2$ und Nullsetzen: \pp
$$\frac{\partial \ell}{\partial \sigma^2} = -\frac{n}{2\sigma^2} + \frac{1}{2(\sigma^2)^2}\sum_{i=1}^n (x_i-\mu)^2 = 0$$

Auflösen nach $\hat{\sigma}^2$: \pp

Mit $\hat{\mu} = \bar{x}$ folgt $\hat{\sigma}^2 = \frac{1}{n}\sum_{i=1}^n (x_i - \bar{x})^2$. \pp

Nachweis dass Maximum (zweite Ableitung negativ): \pp
:::

## Konditionszahlen

Seien $\mathbf{A}, \mathbf{B}$ Matrizen mit passenden Dimensionen. Berechne möglichst gute Schranken für die relativen Konditionszahlen.

###

$f(\mathbf{A}) = \mathbf{A} + \mathbf{B}$

::: {.solution box=2.5}
**Lösung:**

Ansatz mit Definition der Konditionszahl: \p
Es gilt $\kappa_{rel} = \|\mathbf{A}\| / \|\mathbf{A} + \mathbf{B}\|$. \pp
:::

###

$f(\mathbf{A}) = \mathbf{A} \mathbf{B}$

::: {.solution box=2.5}
**Lösung:**

Produktregel anwenden: \p
Es gilt $\kappa_{rel} \le \|\mathbf{A}\|\|\mathbf{B}\| / \|\mathbf{A}\mathbf{B}\|$. \pp
:::

###

Für welche $\mathbf{A}, \mathbf{B}$ sind die Probleme schlecht konditioniert?

::: {.solution box=3}
**Lösung:**

Das Problem a) ist schlecht konditioniert wenn $\mathbf{A} \approx -\mathbf{B}$ (Auslöschung). \pp
Das Problem b) ist schlecht konditioniert wenn $\mathbf{A}\mathbf{B} \approx 0$ (fast singuläres Produkt). \pp
:::

## Integralrechnung

Berechnen Sie das bestimmte Integral:
$$\int_0^{\pi} \sin^2(x) \, dx$$

::: {.solution box=5}
**Lösung:**

Trigonometrische Identität verwenden:
$$\sin^2(x) = \frac{1 - \cos(2x)}{2} \p$$

Integral aufteilen:
$$\int_0^{\pi} \sin^2(x) \, dx = \int_0^{\pi} \frac{1 - \cos(2x)}{2} \, dx \p$$

Stammfunktion bestimmen:
$$= \frac{1}{2}\left[x - \frac{\sin(2x)}{2}\right]_0^{\pi} \pp$$

Grenzen einsetzen:
$$= \frac{1}{2}\left(\pi - 0 - 0 + 0\right) = \frac{\pi}{2} \pp$$

Ergebnis: $\frac{\pi}{2}$ \pp
:::

## Kondition und Stabilität

Erklären Sie den Unterschied zwischen **Kondition** eines Problems und **Stabilität** eines Algorithmus.

::: {.solution}
**Lösung:**

**Kondition** ist eine Eigenschaft des mathematischen Problems selbst: \pp

- Beschreibt, wie empfindlich die Lösung auf kleine Änderungen der Eingabedaten reagiert \p
- Unabhängig vom verwendeten Algorithmus \hp
- Gemessen durch die Konditionszahl $\kappa$ \hp

**Stabilität** ist eine Eigenschaft des Algorithmus: \pp

- Beschreibt, wie sich Rundungsfehler während der Berechnung fortpflanzen \p
- Unterscheidung: vorwärts-stabil vs. rückwärts-stabil \hp
- Ein stabiler Algorithmus für ein gut konditioniertes Problem liefert genaue Ergebnisse \hp
:::
